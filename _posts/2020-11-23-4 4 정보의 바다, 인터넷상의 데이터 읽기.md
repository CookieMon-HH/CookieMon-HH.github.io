---
title : "4.정보의 바다, 인터넷상의 데이터 읽기 "
categories:
  - 파이썬 데이터 분석
# tags:
#  - Python
#  - 데이터 분석
#  - Pandas
date : 2020-11-22
---


인터넷 상의 데이터 읽기 
--- 
- URL 상의 csv 읽기 : Pandas.read_csv(url) 
- 직접 크롤링을 통한 읽기 : request/Selenium 라이브러리를 통한 처리, Pandas.read_html(url,...) (특정 url에서는 내부적으로 requests 라이브러리 활용) 
- Pandas-datareader 라이브러리 : 이또한 내부적으로 requests 라이브러리 활용, 지원데이터소스는 FRED,Nasdaq, YahooFinance,GoogleFinance등이며 정식 API가 아닌 크롤링을 사용하는 것이기때문에 버전에 따라 오류발생 가능  
- seaborn 라이브러리 : 예제용 저장소 : https://github.com/mwaskom/seaborn-data  

Pandas.read_csv
---
- csv 파일을 가져오는 구문

```python

import pandas as pd

#다음의 구문을 통해 인터넷상의 csv 파일을 가져올 수 있다. (예시:Kosdaq 번호 csv파일)
df= pd.read_csv('url', index_col='종목명')
print(df.shape)
df.head() 

df.loc['녹십자엠에스']

```

Pandas.read_html
---

- html문자열 내의 테이블 태그가 있다면 테이블 태그의 내용을 파싱해서 데이터 프레임화 한다.  
- 웹페이지 크롤링을 쉽게 도와주는 라이브러리 이지만 만능은 아니다. (페이상에서 우클릭->페이지 소스보기 에서 내가 찾고자 하는 데이터에 대한 테이블 태그가 있는지 확인해야 한다.) 
- 단, 디도스 프로텍션이 되어있는 경우 동작이 잘 되지 않을수도 있다. 
- 웹페이지 상의 HTML table을 한번에 하기 위한 목적 
- HTML table에 데이터 외의 다른 문자열이 있을경우 곤란 
- 위와같이 곤란한 경우에는 직접 크롤링 하는것이 간편하다. 


- 페이지상에 테이블이 여러개 있을 수 있으므로 read_html 에서는 값을 리스트로 받아온다. 데이터프레임으로 사용하기 위해서는 변환해주어야 한다.  

```python 
#페이지의 테이블 데이터 import 
df_list = pd.read_html('URL', encoding='cp949')   #문자열이 깨지는 경우에는 인코딩부분 추가 

len(df_list)     #read_html은 list의 형식으로 값을 가져오므로 len()함수를 사용하여 확인하면 1일 출력된다.

1

df=df_list[0]    #이와 같이 df_list[0]의 값을 데이터프레임으로 만들어주면 데이터프레임이 된 것을 확인할 수 있다.  
print(df.shape)
df.head

```

Pandas-datareader 
--- 

- 판다스의 별도의 서드파티 리더 
- 판다스 데이터 리더 라이브러리를 설치해야 사용할 수 있다. 
- 외부 API혹은 외부 페이지를 크롤링 하는 것이고 웹페이지 혹은 외부 API는 수시로 바뀔 수 있으므로 항상 최신버전 업그레이드를 해줘야 한다. 
- 명령 프롬프트 혹은 파워쉘에서  pip install--upgrade pandas-datareader 를 통해 설치 

```python 

#pandas data reader를 통해 yahoo finace내의 종목의 데이터를 가져옴 
import pandas_datareader as pdr 
pdr.get_data_yahoo('035420.KS','2018-01-01')

```
